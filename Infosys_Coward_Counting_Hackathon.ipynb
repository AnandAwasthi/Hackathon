{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Infosys_Coward_Counting_Hackathon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO3233iWOydg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_test_dataset_zip = \"/content/drive/My Drive/Google Colab Dataset/ucsdpeds.zip\"\n",
        "model_folder = f'/content/drive/My Drive/icch/model/'\n",
        "model_train_test_folder = '/content/drive/My Drive/icch/train_test/coward_counting_train_test_data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLfz0MJqk0fR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyHQGS1fnbME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r '/content/drive/My Drive/icch/train_test/coward_counting_train_test_data'\n",
        "!mkdir '/content/drive/My Drive/icch/train_test/coward_counting_train_test_data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dg2k-4urmGjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls \"/content/drive/My Drive/Google Colab Dataset\"        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RIhUyD6n8Hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Google Colab Dataset/ucsdpeds.zip\" -d '/content/drive/My Drive/icch/train_test/coward_counting_train_test_data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S_tolEXvZwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls model_train_test_folder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSJJkqrc8f2K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install scipy\n",
        "!pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_3a1v4B9OdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "import random\n",
        "import os\n",
        "from PIL import Image,ImageFilter,ImageDraw\n",
        "import numpy as np\n",
        "import h5py\n",
        "import shutil\n",
        "from PIL import ImageStat\n",
        "import cv2\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from torch.nn import functional as TF\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "import scipy.io as io\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.ndimage.filters import gaussian_filter \n",
        "from scipy import spatial, ndimage \n",
        "import json\n",
        "from matplotlib import cm as CM\n",
        "from image import *\n",
        "\n",
        "import random\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "from image import *\n",
        "import torchvision.transforms.functional as F\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmqZ6UypzVBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian_filter_density(gt):\n",
        "    density = np.zeros(gt.shape, dtype=np.float32)\n",
        "    gt_count = np.count_nonzero(gt)\n",
        "    if gt_count == 0:\n",
        "        return density\n",
        "\n",
        "    pts = np.array(list(zip(np.nonzero(gt)[1], np.nonzero(gt)[0])))\n",
        "    leafsize = 2048\n",
        "\n",
        "    tree = spatial.KDTree(pts.copy(), leafsize=leafsize)\n",
        "\n",
        "    distances, locations = tree.query(pts, k=4)\n",
        "\n",
        "    for i, pt in enumerate(pts):\n",
        "        pt2d = np.zeros(gt.shape, dtype=np.float32)\n",
        "        pt2d[pt[1],pt[0]] = 1.\n",
        "        if gt_count > 1:\n",
        "            sigma = (distances[i][1]+distances[i][2]+distances[i][3])*0.1\n",
        "        else:\n",
        "            sigma = np.average(np.array(gt.shape))/2./2. #case: 1 point\n",
        "        density += ndimage.filters.gaussian_filter(pt2d, sigma, mode='constant')\n",
        "\n",
        "    return density"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJdGn8B80B0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_paths(path_sets, search_extension = '*.jpg'):\n",
        "  \n",
        "  img_paths = []\n",
        "  for path in path_sets:\n",
        "      for img_path in glob.glob(os.path.join(path, search_extension)):\n",
        "          img_paths.append(img_path)\n",
        "  return img_paths\n",
        "\n",
        "\n",
        "def generate_density(image_paths):\n",
        "  for img_path in tqdm(image_paths):\n",
        "      mat = io.loadmat(img_path.replace('.jpg','.mat').replace('images','gt').replace('IMG_','GT_'))\n",
        "      img= plt.imread(img_path)\n",
        "      k = np.zeros((img.shape[0],img.shape[1]))\n",
        "      gt = mat[\"image_info\"][0,0][0,0][0]\n",
        "      for i in range(0,len(gt)):\n",
        "          if int(gt[i][1])<img.shape[0] and int(gt[i][0])<img.shape[1]:\n",
        "              k[int(gt[i][1]),int(gt[i][0])]=1\n",
        "      k = gaussian_filter_density(k)\n",
        "      with h5py.File(img_path.replace('.jpg','.h5').replace('images','gt'), 'w') as hf:\n",
        "              hf['density'] = k\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxGWFucP8w15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDCPOTZfzmmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = model_train_test_folder\n",
        "\n",
        "part_1_train = os.path.join(root,'part_1_final/train_data','images')\n",
        "part_1_test = os.path.join(root,'part_1_final/test_data','images')\n",
        "part_2_train = os.path.join(root,'part_2_final/train_data','images')\n",
        "part_2_test = os.path.join(root,'part_2_final/test_data','images')\n",
        "path_sets_A = [part_1_train,part_1_test]\n",
        "path_sets_B = [part_2_train,part_2_test]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "564Wtl2oSEUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing as mp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNOc3qdXCL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_paths_A = image_paths(path_sets_A)\n",
        "image_paths_B = image_paths(path_sets_B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfQKv9-jT9sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(image_paths_A)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzgp65MDb2pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGcIOWN8bAA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "with Pool(10) as p:\n",
        "  p.map(generate_density, [image_paths_A])\n",
        "\n",
        "with Pool(10) as p:\n",
        "  p.map(generate_density, [image_paths_B])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utpTCLRBirFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_prec1 = 1e6\n",
        "  \n",
        "original_lr = 1e-7\n",
        "lr = 1e-7\n",
        "batch_size    = 1\n",
        "momentum      = 0.95\n",
        "decay         = 5*1e-4\n",
        "start_epoch   = 0\n",
        "epochs = 400\n",
        "steps         = [-1,1,100,150]\n",
        "scales        = [1,1,1,1]\n",
        "workers = 4\n",
        "seed = time.time()\n",
        "print_freq = 30\n",
        "pre = None\n",
        "task = 'a'\n",
        "\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hms9JUwdea-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(img_path,train = True):\n",
        "    gt_path = img_path.replace('.jpg','.h5').replace('images','gt')\n",
        "    img = Image.open(img_path).convert('RGB')\n",
        "    gt_file = h5py.File(gt_path)\n",
        "    target = np.asarray(gt_file['density'])\n",
        "    if False:\n",
        "        crop_size = (img.size[0]/2,img.size[1]/2)\n",
        "        if random.randint(0,9)<= -1:\n",
        "            dx = int(random.randint(0,1)*img.size[0]*1./2)\n",
        "            dy = int(random.randint(0,1)*img.size[1]*1./2)\n",
        "        else:\n",
        "            dx = int(random.random()*img.size[0]*1./2)\n",
        "            dy = int(random.random()*img.size[1]*1./2)\n",
        "        \n",
        "        img = img.crop((dx,dy,crop_size[0]+dx,crop_size[1]+dy))\n",
        "        target = target[dy:crop_size[1]+dy,dx:crop_size[0]+dx]\n",
        "        \n",
        "        if random.random()>0.8:\n",
        "            target = np.fliplr(target)\n",
        "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    \n",
        "    target = cv2.resize(target,(target.shape[1]// 8,target.shape[0]// 8),interpolation = cv2.INTER_CUBIC)*64    \n",
        "    \n",
        "    return img,target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awK8yITsdzh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_net(fname, net):\n",
        "    with h5py.File(fname, 'w') as h5f:\n",
        "        for k, v in net.state_dict().items():\n",
        "            h5f.create_dataset(k, data=v.cpu().numpy())\n",
        "def load_net(fname, net):\n",
        "    with h5py.File(fname, 'r') as h5f:\n",
        "        for k, v in net.state_dict().items():        \n",
        "            param = torch.from_numpy(np.asarray(h5f[k]))         \n",
        "            v.copy_(param)\n",
        "            \n",
        "def save_checkpoint(state, is_best,task_id, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, task_id+filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(task_id+filename, task_id+'ccih.pth.tar') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nbBcu6vBI9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CCNN(nn.Module):\n",
        "    def __init__(self, load_weights=False):\n",
        "        super(CCNN, self).__init__()\n",
        "        self.seen = 0\n",
        "        self.encode_layer = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(3, 256, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(3, 256, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(3, 256, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(3, 512, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(3, 512, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(3, 512, kernel_size=3, padding=1,dilation = 1),\n",
        "            conv2d, nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.decode_layer = nn.Sequential(\n",
        "            nn.Conv2d(3, 512, kernel_size=3, padding=1,dilation = 1),\n",
        "            nn.Conv2d(3, 512, kernel_size=3, padding=1,dilation = 1),\n",
        "            nn.Conv2d(3, 512, kernel_size=3, padding=1,dilation = 1),\n",
        "            nn.Conv2d(3, 256, kernel_size=3, padding=1,dilation = 1),\n",
        "            nn.Conv2d(3, 256, kernel_size=3, padding=1,dilation = 1),\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1,dilation = 1)\n",
        "        )\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "        if not load_weights:\n",
        "            mod = models.vgg16(pretrained = True)\n",
        "            self._initialize_weights()\n",
        "            for i in range(len(self.frontend.state_dict().items())):\n",
        "              list(self.frontend.state_dict().items())[i][1].data[:] = list(mod.state_dict().items())[i][1].data[:]\n",
        "      \n",
        "    def forward(self,x):\n",
        "        x = self.encode_layer(x)\n",
        "        x = self.decode_layer(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, 0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyaNUixzrVNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip_gradient(model, clip_value):\n",
        "    params = list(filter(lambda p: p.grad is not None, model.parameters()))\n",
        "    for p in params:\n",
        "        p.grad.data.clamp_(-clip_value, clip_value)\n",
        "\n",
        "def train(train_list, model, criterion, optimizer, epoch):\n",
        "  \n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        listDataset(train_list,\n",
        "                       shuffle=True,\n",
        "                       transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225]),\n",
        "                   ]), \n",
        "                       train=True, \n",
        "                       seen=model.seen,\n",
        "                       batch_size=batch_size,\n",
        "                       num_workers=workers),\n",
        "        batch_size=batch_size)\n",
        "    print('epoch %d, processed %d samples, lr %.10f' % (epoch, epoch * len(train_loader.dataset), lr))\n",
        "    \n",
        "    model.train()\n",
        "    end = time.time()\n",
        "    \n",
        "    for i, (img, target) in enumerate(train_loader):\n",
        "        data_time.update(time.time() - end)\n",
        "        img = img.cuda()\n",
        "        img = Variable(img)\n",
        "        \n",
        "        target = target.type(torch.FloatTensor).unsqueeze(0).cuda()\n",
        "        target = torch.autograd.Variable(target)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(img)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        clip_gradient(model, 1e-1)\n",
        "        optimizer.step()    \n",
        "        \n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        \n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  .format(\n",
        "                   epoch, i, len(train_loader), loss=loss.item()))\n",
        "            \n",
        "def validate(val_list, model, criterion):\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "    listDataset(val_list,\n",
        "                   shuffle=False,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225]),\n",
        "                   ]),  train=False),\n",
        "    batch_size= batch_size)    \n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    mae = 0\n",
        "    \n",
        "    for i,(img, target) in enumerate(test_loader):\n",
        "        img = img.cuda()\n",
        "        img = Variable(img)\n",
        "        output = model(img)\n",
        "        \n",
        "        mae += abs(output.data.sum()-target.sum().type(torch.FloatTensor).cuda())\n",
        "        \n",
        "    mae = mae/len(test_loader)    \n",
        "    print(' * MAE {mae:.3f} '\n",
        "              .format(mae=mae))\n",
        "\n",
        "    return mae    \n",
        "        \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWAzaww37dCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class listDataset(Dataset):\n",
        "    def __init__(self, root, shape=None, shuffle=True, transform=None,  train=False, seen=0, batch_size=1, num_workers=4):\n",
        "        if train:\n",
        "            root = root *4\n",
        "        random.shuffle(root)\n",
        "        \n",
        "        self.nSamples = len(root)\n",
        "        self.lines = root\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "        self.shape = shape\n",
        "        self.seen = seen\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.nSamples\n",
        "    def __getitem__(self, index):\n",
        "        assert index <= len(self), 'index range error' \n",
        "        \n",
        "        img_path = self.lines[index]\n",
        "        \n",
        "        img,target = load_data(img_path,self.train)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img,target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUDGy_AL9aIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_list = image_paths([part_A_train, part_B_train])\n",
        "val_list = image_paths([part_A_test, part_B_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNuVe0KAJDj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_prec1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q4OWmJZ-VC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_training(train_dataset, validation_dataset):\n",
        "  model = CCNN()\n",
        "  model = model.cuda()\n",
        "  criterion = nn.MSELoss(reduction='mean')\n",
        "\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr,\n",
        "                                momentum=momentum,\n",
        "                                weight_decay=decay)\n",
        "  \n",
        "  if pre:\n",
        "    if os.path.isfile(pre):\n",
        "      checkpoint = torch.load(pre)\n",
        "      args.start_epoch = checkpoint['epoch']\n",
        "      best_prec1 = checkpoint['best_prec1']\n",
        "      model.load_state_dict(checkpoint['state_dict'])\n",
        "      optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    else:\n",
        "      print(\"=> no checkpoint found at '{}'\".format(pre))\n",
        "  \n",
        "    \n",
        "  for epoch in range(start_epoch, epochs):\n",
        "    train(train_dataset, model, criterion, optimizer, epoch)\n",
        "    prec1 = validate(validation_dataset, model, criterion)\n",
        "    is_best = prec1 < best_prec1\n",
        "\n",
        "    best_prec1 = min(prec1, best_prec1)\n",
        "    print(' * best MAE {mae:.3f} '\n",
        "          .format(mae=best_prec1))\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch + 1,\n",
        "        'arch': pre,\n",
        "        'state_dict': model.state_dict(),\n",
        "        'best_prec1': best_prec1,\n",
        "        'optimizer' : optimizer.state_dict(),\n",
        "    }, is_best,task)\n",
        "\n",
        "  save_net(f'/content/drive/My Drive/icch/model/{model_file_name}'.format(model_file_name = task+'_ccih.pth.tar'), model)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMl68oYthBm6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run_training(train_list, val_list)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}